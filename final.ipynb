{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b388891",
   "metadata": {},
   "source": [
    "# CIS4930 -- Final Project\n",
    "## Developed by: Chloe Fandino (Team Leader), Ashley James, Madelyne Wirbel, Chloe Nolan, Christopher Enlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961bb43",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81630e6b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3080896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports here :)\n",
    "\n",
    "# TODO: DELETE ---> any imports that don't end up getting used by the end of the project !!!!\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3635f",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698fd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('OnlineNewsPopularity.csv') # import the data from the csv file --> convert to df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4edfe",
   "metadata": {},
   "source": [
    "### Exploration of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 100) # for purposes of looking at data --> need to see all rows\n",
    "\n",
    "# basic intitial looks at the dataset\n",
    "print(df.shape)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from column names\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27bb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist()) # print out all of the available columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # null values? --> NONE :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25398568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() # duplicate values? --> NONE :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539006c-7e46-4a25-8098-44037eeeaab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any infinities exist in the dataframe\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "has_inf = np.isinf(numeric_df.to_numpy()).any()\n",
    "\n",
    "print(has_inf) # will need to handle in cleaning\n",
    "inf_cols = numeric_df.columns[np.isinf(numeric_df.to_numpy()).any(axis=0)].tolist()\n",
    "print(\"Columns with inf:\", inf_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a799c4bc",
   "metadata": {},
   "source": [
    "#### Visualization of the target variable --> shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of shares\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df[\"shares\"], bins=50)\n",
    "plt.title(\"Distribution of Shares (Raw Scale)\")\n",
    "plt.xlabel(\"Shares\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yscale(\"log\")  # long tail\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of raw shares --> view of the outliers\n",
    "sns.boxplot(x = df[\"shares\"])\n",
    "plt.title(\"Boxplot of Shares (Visualization of Outliers)\")\n",
    "plt.ylabel(\"Shares\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9071771",
   "metadata": {},
   "source": [
    "#### Visualizations of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63373d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of key numerical features\n",
    "key_cols = [\"n_tokens_title\", \"n_tokens_content\", \"num_imgs\", \"num_hrefs\"]\n",
    "\n",
    "for col in key_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(df[col], bins=50)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8bb7e3",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34de976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exploration of potentially non-predictive features\n",
    "df = df.drop(columns=['url', 'timedelta'], errors='ignore') # url is a title and number of days since posted until added to the dataset --> no predictive qualities\n",
    "\n",
    "# feature engineering\n",
    "df['rate_positive_words'] = df['global_rate_positive_words'] / (df['n_tokens_content'] + 1)\n",
    "df['rate_negative_words'] = df['global_rate_negative_words'] / (df['n_tokens_content'] + 1)\n",
    "df['emotional_polarity'] = df['global_sentiment_polarity'].abs()\n",
    "df['title_body_sentiment_ratio'] = df['title_sentiment_polarity'] / (df['global_sentiment_polarity'] + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data in two --> based on median\n",
    "median_shares = df['shares'].median()\n",
    "print(f\"Splitting data at median shares: {median_shares}\")\n",
    "\n",
    "def categorize(x):\n",
    "    return 1 if x > median_shares else 0\n",
    "\n",
    "df['y'] = df['shares'].apply(categorize)\n",
    "\n",
    "# define X and y \n",
    "X = df.drop(columns=['shares', 'y'])\n",
    "y = df['y']\n",
    "\n",
    "binary_cols = [col for col in X.columns if \"data_channel\" in col or \"weekday\" in col or \"is_weekend\" in col]\n",
    "# ensure binary cols are actually integers\n",
    "for col in binary_cols:\n",
    "    X[col] = X[col].astype(int)\n",
    "\n",
    "numeric_cols = [col for col in X.columns if col not in binary_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> test-train-split <-- DO NOT EDIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHLOE pearson correlation coefficient\n",
    "corr_matrix = X_train[numeric_cols].corr(method='pearson').abs()\n",
    "\n",
    "# visualization of highly correlated features\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    cmap='coolwarm',\n",
    "    annot=False,\n",
    "    linewidths=0.3,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    "    square=True\n",
    ")\n",
    "plt.title(\"Pearson Correlation Heatmap of Numeric Features (absolute value)\")\n",
    "plt.show()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]\n",
    "\n",
    "print(f\"Dropping {len(to_drop)} columns due to correlation: {to_drop}\")\n",
    "\n",
    "X_train = X_train.drop(columns=to_drop)\n",
    "X_test = X_test.drop(columns=to_drop)\n",
    "numeric_cols = [c for c in numeric_cols if c not in to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f9d86",
   "metadata": {},
   "source": [
    "#### Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize and count anomalies\n",
    "def anomaly_detection(feature, visualize):\n",
    "    # first boxplot to see potential outliers\n",
    "    if visualize:\n",
    "        sns.boxplot(x = df[feature], color = 'purple')\n",
    "        plt.title(feature)\n",
    "        plt.show()\n",
    "\n",
    "    # second calculate outliers based on IQR\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    anomalies = df[(df[feature] < lower) | (df[feature] > upper)]\n",
    "    print('Anomalies: \\n', anomalies) # prints a list of potential anomalies\n",
    "\n",
    "    num_anomalies = anomalies.shape[0]\n",
    "    return num_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78744fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE OUTLIER HANDLING --> visualize outliers\n",
    "cols_remaining = df.columns.tolist() # what columns are left in the dataset\n",
    "\n",
    "num_anomalies_1 = []\n",
    "\n",
    "# for each of the remaining columns print the anomalies and see if there needs to be any adjustments made --> generally high rates of anomalies\n",
    "for col in cols_remaining:\n",
    "    num = anomaly_detection(col, True)\n",
    "    num_anomalies_1.append(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1b0da",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHLOE handling skew and outliers\n",
    "scaler = RobustScaler()\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# used later\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()\n",
    "y_train_original = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfa28d",
   "metadata": {},
   "source": [
    "#### Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHLOE TRAIN SMOTE NAN\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "#CLASS BALANCING (SMOTE)\n",
    "cat_indices = [X_train.columns.get_loc(c) for c in binary_cols if c in X_train.columns]\n",
    "sm = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfccfad7",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHLOE FEATURE SELECTION\n",
    "selector_model = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1, random_state=42)\n",
    "selector_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "selection = SelectFromModel(selector_model, threshold=\"1.25*median\", prefit=True)\n",
    "\n",
    "# Transform\n",
    "X_train = pd.DataFrame(\n",
    "    selection.transform(X_train_res),\n",
    "    columns=X_train_res.columns[selection.get_support()]\n",
    ")\n",
    "X_test = pd.DataFrame(\n",
    "    selection.transform(X_test),\n",
    "    columns=X_train_res.columns[selection.get_support()]\n",
    ")\n",
    "\n",
    "y_train = y_train_res\n",
    "\n",
    "selected_features_names = X_train.columns\n",
    "print(f\"Selected {len(selected_features_names)} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931158e7-7502-4ae6-ba92-7cec30a8d848",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to declare the variable once\n",
    "labels = ['Not Viral', 'Viral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb95385",
   "metadata": {},
   "source": [
    "Note - grid search has been commented out to reduce runtime. The best hyperparameters found are commented at the bottom of the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2e11f",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2388a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression hyperparameter grid\n",
    "# lr_params = {\n",
    "#     'C': [0.01, 0.1, 1, 10],\n",
    "#     'solver': ['lbfgs'],\n",
    "#     'penalty': ['l2'],\n",
    "#     'max_iter': [1000]\n",
    "# }\n",
    "\n",
    "# lr_grid = GridSearchCV(\n",
    "#     LogisticRegression(),\n",
    "#     lr_params,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# lr_grid.fit(X_train, y_train.to_numpy())\n",
    "\n",
    "# print(\"Best LR Params:\", lr_grid.best_params_)\n",
    "# print(\"Best LR Score:\", lr_grid.best_score_)\n",
    "\n",
    "# # Final tuned LR model\n",
    "# lr_best = lr_grid.best_estimator_\n",
    "# y_pred_lr_tuned = lr_best.predict(X_test)\n",
    "\n",
    "# # Best LR Params: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best hyperparameters\n",
    "best_lr_model = LogisticRegression(\n",
    "    C=0.1,\n",
    "    max_iter=1000,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "best_lr_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# make predictions\n",
    "y_pred_lr = best_lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c46aa-f004-49fc-92c0-0823c5598543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate linear regression performance\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test.values.ravel(), y_pred_lr, target_names=labels))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Purples', xticklabels = labels, yticklabels = labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b934d",
   "metadata": {},
   "source": [
    "#### 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6925d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the optimal value of k\n",
    "# k_values = range(1, 40)\n",
    "# accuracy_scores = []\n",
    "\n",
    "# for k in k_values:\n",
    "#     # Build KNN classifier for each k\n",
    "#     knn = KNeighborsClassifier(n_neighbors = k, weights = 'uniform')\n",
    "#     knn.fit(X_train, y_train.to_numpy())\n",
    "    \n",
    "#     # Predict on test set\n",
    "#     pred = knn.predict(X_test)\n",
    "    \n",
    "#     # Calculate accuracy\n",
    "#     acc = accuracy_score(y_test.to_numpy(), pred)\n",
    "#     accuracy_scores.append(acc)\n",
    "\n",
    "# plt.plot(k_values, accuracy_scores, marker='o', linestyle='dashed', color='green')\n",
    "# plt.xlabel(\"K Value\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Finding Optimal K for Binary Classification\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# best_k = k_values[np.argmax(accuracy_scores)]\n",
    "# print(f\"Best K found: {best_k} with Accuracy: {max(accuracy_scores):.4f}\")\n",
    "\n",
    "# # Best K found: 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ffb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train knn with optimal k\n",
    "knn_best = KNeighborsClassifier(n_neighbors=31, weights='uniform')\n",
    "\n",
    "# Fit the model\n",
    "knn_best.fit(X_train, y_train.values.ravel()) \n",
    "\n",
    "# Prediction\n",
    "y_pred_knn = knn_best.predict(X_test)\n",
    "\n",
    "# visualize success of knn\n",
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"KNN Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "print(f\"--- FINAL KNN RESULTS (K=31) ---\")\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test.values.ravel(), y_pred_knn, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d8955-93d3-4928-9411-6503534c3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_knn = knn_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test.values.ravel(), y_prob_knn)\n",
    "\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'KNN (k=37) AUC = {roc_auc_knn:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: K-Nearest Neighbors')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b624315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "X_train_raw_df = pd.DataFrame(X_train_original)   # copy before smote + feature selection\n",
    "y_train_raw_df = pd.Series(y_train_original)\n",
    "\n",
    "# Subsample\n",
    "X_vis = X_train_raw_df.sample(3000, random_state=42)\n",
    "y_vis = y_train_raw_df.loc[X_vis.index]\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_vis)\n",
    "X_test_pca = pca.transform(X_test_original)\n",
    "\n",
    "# KNN for decision boundary\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train_pca, y_vis.values.ravel())\n",
    "\n",
    "# Meshgrid\n",
    "h = 1\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(\n",
    "    np.arange(x_min, x_max, h),\n",
    "    np.arange(y_min, y_max, h)\n",
    ")\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=ListedColormap(['#FFCCCC', '#CCCCFF']), alpha=0.3)\n",
    "plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1],\n",
    "            c=y_test.values.ravel(),\n",
    "            cmap=ListedColormap(['#FF0000', '#0000FF']),\n",
    "            edgecolor='k', s=30, alpha=0.7)\n",
    "plt.title(\"KNN Decision Boundary (PCA of Original Data)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab3cd8-1bc5-4965-a6e5-51431f5a6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "run() test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df76823",
   "metadata": {},
   "source": [
    "#### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05210935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forest hyperparameter grid\n",
    "# rf_params = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [10, 15, 20],\n",
    "#     'max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# rf_grid = GridSearchCV(\n",
    "#     RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "#     rf_params,\n",
    "#     cv=3,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# rf_grid.fit(X_train, y_train.to_numpy())\n",
    "\n",
    "# print(\"Best RF Params:\", rf_grid.best_params_)\n",
    "# print(\"Best RF Score:\", rf_grid.best_score_)\n",
    "\n",
    "# # Final tuned RF model\n",
    "# rf_best = rf_grid.best_estimator_\n",
    "# y_pred_rf_tuned = rf_best.predict(X_test)\n",
    "\n",
    "# # Best RF Params: {'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with tuned parameters\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "best_rf_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test.values.ravel(), y_pred_rf, target_names=labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test.values.ravel(), y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "importances = best_rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "feature_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_df = feature_df.sort_values(by='Importance', ascending=False).head(15)\n",
    "print(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the trained model\n",
    "importances = best_rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to organize them\n",
    "# Assuming X_train was a DataFrame originally. If it was a numpy array, \n",
    "# we generate generic names Feature_0, Feature_1, etc.\n",
    "try:\n",
    "    feature_names = X_train.columns\n",
    "except:\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "feature_imp_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Top 20 Features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df.head(20), palette='viridis')\n",
    "plt.title(\"Top 20 Features driving the Random Forest\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature Name\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 Most Important Features:\")\n",
    "print(feature_imp_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daf3c5",
   "metadata": {},
   "source": [
    "#### 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model\n",
    "# xgb = XGBClassifier(random_state=42, objective='binary:logistic', n_jobs=-1)\n",
    "\n",
    "# # Define hyperparameter grid\n",
    "# xgb_param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 6, 10],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'subsample': [0.7, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Grid search with CV\n",
    "# xgb_grid = GridSearchCV(\n",
    "#     xgb,\n",
    "#     xgb_param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best XGBoost Params:\", xgb_grid.best_params_)\n",
    "# print(\"Best XGBoost Score:\", xgb_grid.best_score_)\n",
    "\n",
    "# # Best XGBoost Params: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49463b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_best_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=labels))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"XGBoost Binary Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd1ca90",
   "metadata": {},
   "source": [
    "#### 5. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# estimators = [\n",
    "#     ('rf', best_rf_model),  # from tuned Random Forest\n",
    "#     ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
    "#     ('lr', LogisticRegression(random_state=42))\n",
    "# ]\n",
    "\n",
    "# stacking_model = StackingClassifier(\n",
    "#     estimators=estimators,\n",
    "#     final_estimator=LogisticRegression(),\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# param_grid = {\n",
    "#     'final_estimator__C': [0.01, 0.1, 1, 10]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(stacking_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "# grid.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# stack_best = grid.best_estimator_\n",
    "# y_pred_stack = stack_best.predict(X_test)\n",
    "\n",
    "# print(\"Best C for final estimator:\", grid.best_params_['final_estimator__C'])\n",
    "\n",
    "# # Best C for final estimator: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95223f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base learners using your tuned models\n",
    "estimators = [\n",
    "    ('rf', best_rf_model),  # tuned Random Forest\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "]\n",
    "\n",
    "# Define the stacking model with the best final estimator parameter\n",
    "stacking_best_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(C=1, random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "stacking_best_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred_stack = stacking_best_model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test.values.ravel(), y_pred_stack, target_names=labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_stack = confusion_matrix(y_test.values.ravel(), y_pred_stack)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_stack, annot=True, fmt='d', cmap='Purples', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Stacking Classifier Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability_stacking = stacking_best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr_stack, tpr_stack, thresholds_stack = roc_curve(y_test.values.ravel(), y_probability_stacking)\n",
    "\n",
    "roc_auc_stack = auc(fpr_stack, tpr_stack)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_stack, tpr_stack, color='purple', lw=2, label=f'Stacking AUC = {roc_auc_stack:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: Stacking Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20156b14",
   "metadata": {},
   "source": [
    "#### 6. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define parameter grid\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'loss': ['hinge', 'squared_hinge'],\n",
    "#     'max_iter': [1000, 5000, 10000]\n",
    "# }\n",
    "\n",
    "# # GridSearchCV\n",
    "# grid = GridSearchCV(\n",
    "#     estimator=LinearSVC(random_state=42),\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,                  # 5-fold cross-validation\n",
    "#     scoring='accuracy',    # you can also try 'f1' if dataset is imbalanced\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # fit\n",
    "# grid.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# # best model\n",
    "# best_svm = grid.best_estimator_\n",
    "\n",
    "# print(\"Best hyperparameters:\", grid.best_params_)\n",
    "\n",
    "# # Best hyperparameters: {'C': 0.1, 'loss': 'squared_hinge', 'max_iter': 1000}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ba852",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_model = LinearSVC(\n",
    "    C=0.1,\n",
    "    loss='squared_hinge',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_svm_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred_svm = best_svm_model.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test.values.ravel(), y_pred_svm, target_names=labels))\n",
    "\n",
    "cm_svm = confusion_matrix(y_test.values.ravel(), y_pred_svm)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Oranges', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"LinearSVC Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability_svm = best_svm_model.decision_function(X_test)\n",
    "\n",
    "fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test.values.ravel(), y_probability_svm)\n",
    "\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'SVM AUC = {roc_auc_svm:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: Support Vector Machine (SVM)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3ae9d",
   "metadata": {},
   "source": [
    "#### 7. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nn architecture\n",
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self, input_dim, dropout, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim,input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor  = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fe21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find best hyperparameters\n",
    "# param_grid = {\n",
    "#     \"lr\": [1e-2, 5e-2, 1e-3],\n",
    "#     \"dropout\": [0.2, 0.3, 0.5],\n",
    "#     \"batch_size\": [32, 64]\n",
    "# }\n",
    "\n",
    "# best_acc = 0\n",
    "# best_params = None\n",
    "# best_model = None\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for lr in param_grid[\"lr\"]:\n",
    "#     for dropout in param_grid[\"dropout\"]:\n",
    "#         for batch in param_grid[\"batch_size\"]:\n",
    "#             train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "\n",
    "#             model = ClassificationNN(\n",
    "#                 input_dim=X_train_tensor.shape[1],\n",
    "#                 dropout=dropout,\n",
    "#                 num_classes=2\n",
    "#             )\n",
    "            \n",
    "#             optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#             # train for a few epochs\n",
    "#             model.train()\n",
    "#             for epoch in range(5):  \n",
    "#                 for X_batch, y_batch in train_loader:\n",
    "#                     optimizer.zero_grad()\n",
    "#                     outputs = model(X_batch)\n",
    "#                     loss = criterion(outputs, y_batch)\n",
    "#                     loss.backward()\n",
    "#                     optimizer.step()\n",
    "\n",
    "#             # evaluate on test set\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = model(X_test_tensor)\n",
    "#                 preds = torch.argmax(outputs, dim=1)\n",
    "#                 acc = (preds == y_test_tensor).float().mean().item()\n",
    "\n",
    "#             if acc > best_acc:\n",
    "#                 best_acc = acc\n",
    "#                 best_params = (lr, dropout, batch)\n",
    "#                 best_model = model\n",
    "\n",
    "# print(\"Best Neural Network Params:\")\n",
    "# print(f\"Learning Rate: {best_params[0]}\")\n",
    "# print(f\"Dropout: {best_params[1]}\")\n",
    "# print(f\"Batch Size: {best_params[2]}\")\n",
    "# print(f\"Validation Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "# # Best Neural Network Params:\n",
    "# # Learning Rate: 0.001\n",
    "# # Dropout: 0.2\n",
    "# # Batch Size: 32\n",
    "# # Validation Accuracy: 0.6519\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationNN(X_train_tensor.shape[1], 0.2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Test loss\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            running_test_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    test_loss = running_test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "#evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test_tensor.numpy(), y_pred.numpy(), target_names=labels))\n",
    "\n",
    "cm = confusion_matrix(y_test_tensor.numpy(), y_pred.numpy())\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.title(\"Training vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc629742",
   "metadata": {},
   "source": [
    "#### 8. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f95902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter grid for Decision Tree\n",
    "# dt_params = {\n",
    "#     'max_depth': [5, 10, 15, 20, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'criterion': ['gini', 'entropy']\n",
    "# }\n",
    "\n",
    "# # GridSearchCV to find best parameters\n",
    "# dt_grid = GridSearchCV(\n",
    "#     DecisionTreeClassifier(random_state=42),\n",
    "#     dt_params,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit to training data\n",
    "# dt_grid.fit(X_train, y_train.to_numpy())\n",
    "\n",
    "# # Best parameters and score\n",
    "# print(\"Best Decision Tree Params:\", dt_grid.best_params_)\n",
    "# print(\"Best Decision Tree Score:\", dt_grid.best_score_)\n",
    "\n",
    "# # Final tuned model\n",
    "# dt_best = dt_grid.best_estimator_\n",
    "# y_pred_dt = dt_best.predict(X_test)\n",
    "\n",
    "# # Best Decision Tree Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree model with best parameters\n",
    "dt_best_model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "dt_best_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_best_model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test.values.ravel(), y_pred_dt, target_names=labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_dt = confusion_matrix(y_test.values.ravel(), y_pred_dt)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Decision Tree Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability_stacking = stacking_best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr_stack, tpr_stack, thresholds_stack = roc_curve(y_test.values.ravel(), y_probability_stacking)\n",
    "\n",
    "roc_auc_stack = auc(fpr_stack, tpr_stack)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_stack, tpr_stack, color='purple', lw=2, label=f'Stacking AUC = {roc_auc_stack:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: Stacking Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001552ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "importances = dt_best_model.feature_importances_\n",
    "try:\n",
    "    feature_names = X_train.columns\n",
    "except AttributeError:\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "feature_imp_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Top 20 Features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df.head(20), palette='viridis')\n",
    "plt.title(\"Top 20 Features driving Decision Tree\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature Name\")\n",
    "plt.show()\n",
    "\n",
    "# Print top 5 features\n",
    "print(\"Top 5 Most Important Features:\")\n",
    "print(feature_imp_df.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
